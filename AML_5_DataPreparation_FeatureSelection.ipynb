{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"colab":{"name":"AML_5_DataPreparation_FeatureSelection.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Op2yF_XGRN5D","colab_type":"text"},"source":["# Feature Selection for ML"]},{"cell_type":"markdown","metadata":{"id":"3Q9aUfG6RN5E","colab_type":"text"},"source":["We discuss feature selection techniques that you can use to prepare your ML data in Python with scikit-learn. \n","\n","Focus will be on:\n","1. Univariate Selection\n","2. Recursive Feature Elimination\n","3. Feature Importance\n","4. Principal Component Analysis"]},{"cell_type":"markdown","metadata":{"id":"uR9VV3FARN5F","colab_type":"text"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"3ubyEy6FRN5G","colab_type":"text"},"source":["Discussed in the hands-on.\n","\n","3 main goals/benefits:\n","1. ***Reduction of Overfitting***\n","1. ***Improvement of Accuracy***\n","1. ***Reduction of Training Time***\n"]},{"cell_type":"markdown","metadata":{"id":"rsBL2p7Mpo7W","colab_type":"text"},"source":["\n","More about feature selection with scikit-learn can be found [here](http://scikit-learn.org/stable/modules/feature_selection.html)."]},{"cell_type":"markdown","metadata":{"id":"6NyHWASMpbyq","colab_type":"text"},"source":["## 0. Import the data"]},{"cell_type":"code","metadata":{"id":"egGmPYr6pblR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fa93109d-4cd3-477f-c9a1-f1371341c133","executionInfo":{"status":"ok","timestamp":1587724417390,"user_tz":-120,"elapsed":631,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/dbonacorsi/AML_basic_AA1920/master/datasets/pima-indians-diabetes.data.csv'\n","\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","data = pd.read_csv(url, names=names)\n","data"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     preg  plas  pres  skin  test  mass   pedi  age  class\n","0       6   148    72    35     0  33.6  0.627   50      1\n","1       1    85    66    29     0  26.6  0.351   31      0\n","2       8   183    64     0     0  23.3  0.672   32      1\n","3       1    89    66    23    94  28.1  0.167   21      0\n","4       0   137    40    35   168  43.1  2.288   33      1\n","5       5   116    74     0     0  25.6  0.201   30      0\n","6       3    78    50    32    88  31.0  0.248   26      1\n","7      10   115     0     0     0  35.3  0.134   29      0\n","8       2   197    70    45   543  30.5  0.158   53      1\n","9       8   125    96     0     0   0.0  0.232   54      1\n","10      4   110    92     0     0  37.6  0.191   30      0\n","11     10   168    74     0     0  38.0  0.537   34      1\n","12     10   139    80     0     0  27.1  1.441   57      0\n","13      1   189    60    23   846  30.1  0.398   59      1\n","14      5   166    72    19   175  25.8  0.587   51      1\n","15      7   100     0     0     0  30.0  0.484   32      1\n","16      0   118    84    47   230  45.8  0.551   31      1\n","17      7   107    74     0     0  29.6  0.254   31      1\n","18      1   103    30    38    83  43.3  0.183   33      0\n","19      1   115    70    30    96  34.6  0.529   32      1\n","20      3   126    88    41   235  39.3  0.704   27      0\n","21      8    99    84     0     0  35.4  0.388   50      0\n","22      7   196    90     0     0  39.8  0.451   41      1\n","23      9   119    80    35     0  29.0  0.263   29      1\n","24     11   143    94    33   146  36.6  0.254   51      1\n","25     10   125    70    26   115  31.1  0.205   41      1\n","26      7   147    76     0     0  39.4  0.257   43      1\n","27      1    97    66    15   140  23.2  0.487   22      0\n","28     13   145    82    19   110  22.2  0.245   57      0\n","29      5   117    92     0     0  34.1  0.337   38      0\n","..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n","738     2    99    60    17   160  36.6  0.453   21      0\n","739     1   102    74     0     0  39.5  0.293   42      1\n","740    11   120    80    37   150  42.3  0.785   48      1\n","741     3   102    44    20    94  30.8  0.400   26      0\n","742     1   109    58    18   116  28.5  0.219   22      0\n","743     9   140    94     0     0  32.7  0.734   45      1\n","744    13   153    88    37   140  40.6  1.174   39      0\n","745    12   100    84    33   105  30.0  0.488   46      0\n","746     1   147    94    41     0  49.3  0.358   27      1\n","747     1    81    74    41    57  46.3  1.096   32      0\n","748     3   187    70    22   200  36.4  0.408   36      1\n","749     6   162    62     0     0  24.3  0.178   50      1\n","750     4   136    70     0     0  31.2  1.182   22      1\n","751     1   121    78    39    74  39.0  0.261   28      0\n","752     3   108    62    24     0  26.0  0.223   25      0\n","753     0   181    88    44   510  43.3  0.222   26      1\n","754     8   154    78    32     0  32.4  0.443   45      1\n","755     1   128    88    39   110  36.5  1.057   37      1\n","756     7   137    90    41     0  32.0  0.391   39      0\n","757     0   123    72     0     0  36.3  0.258   52      1\n","758     1   106    76     0     0  37.5  0.197   26      0\n","759     6   190    92     0     0  35.5  0.278   66      1\n","760     2    88    58    26    16  28.4  0.766   22      0\n","761     9   170    74    31     0  44.0  0.403   43      1\n","762     9    89    62     0     0  22.5  0.142   33      0\n","763    10   101    76    48   180  32.9  0.171   63      0\n","764     2   122    70    27     0  36.8  0.340   27      0\n","765     5   121    72    23   112  26.2  0.245   30      0\n","766     1   126    60     0     0  30.1  0.349   47      1\n","767     1    93    70    31     0  30.4  0.315   23      0\n","\n","[768 rows x 9 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preg</th>\n","      <th>plas</th>\n","      <th>pres</th>\n","      <th>skin</th>\n","      <th>test</th>\n","      <th>mass</th>\n","      <th>pedi</th>\n","      <th>age</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>116</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25.6</td>\n","      <td>0.201</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3</td>\n","      <td>78</td>\n","      <td>50</td>\n","      <td>32</td>\n","      <td>88</td>\n","      <td>31.0</td>\n","      <td>0.248</td>\n","      <td>26</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>10</td>\n","      <td>115</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.3</td>\n","      <td>0.134</td>\n","      <td>29</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>197</td>\n","      <td>70</td>\n","      <td>45</td>\n","      <td>543</td>\n","      <td>30.5</td>\n","      <td>0.158</td>\n","      <td>53</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>8</td>\n","      <td>125</td>\n","      <td>96</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.232</td>\n","      <td>54</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>4</td>\n","      <td>110</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37.6</td>\n","      <td>0.191</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>10</td>\n","      <td>168</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>0.537</td>\n","      <td>34</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>10</td>\n","      <td>139</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>27.1</td>\n","      <td>1.441</td>\n","      <td>57</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>189</td>\n","      <td>60</td>\n","      <td>23</td>\n","      <td>846</td>\n","      <td>30.1</td>\n","      <td>0.398</td>\n","      <td>59</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5</td>\n","      <td>166</td>\n","      <td>72</td>\n","      <td>19</td>\n","      <td>175</td>\n","      <td>25.8</td>\n","      <td>0.587</td>\n","      <td>51</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>7</td>\n","      <td>100</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.0</td>\n","      <td>0.484</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0</td>\n","      <td>118</td>\n","      <td>84</td>\n","      <td>47</td>\n","      <td>230</td>\n","      <td>45.8</td>\n","      <td>0.551</td>\n","      <td>31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>7</td>\n","      <td>107</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29.6</td>\n","      <td>0.254</td>\n","      <td>31</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1</td>\n","      <td>103</td>\n","      <td>30</td>\n","      <td>38</td>\n","      <td>83</td>\n","      <td>43.3</td>\n","      <td>0.183</td>\n","      <td>33</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>70</td>\n","      <td>30</td>\n","      <td>96</td>\n","      <td>34.6</td>\n","      <td>0.529</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>3</td>\n","      <td>126</td>\n","      <td>88</td>\n","      <td>41</td>\n","      <td>235</td>\n","      <td>39.3</td>\n","      <td>0.704</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>8</td>\n","      <td>99</td>\n","      <td>84</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.4</td>\n","      <td>0.388</td>\n","      <td>50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>7</td>\n","      <td>196</td>\n","      <td>90</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39.8</td>\n","      <td>0.451</td>\n","      <td>41</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>9</td>\n","      <td>119</td>\n","      <td>80</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>29.0</td>\n","      <td>0.263</td>\n","      <td>29</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>11</td>\n","      <td>143</td>\n","      <td>94</td>\n","      <td>33</td>\n","      <td>146</td>\n","      <td>36.6</td>\n","      <td>0.254</td>\n","      <td>51</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>10</td>\n","      <td>125</td>\n","      <td>70</td>\n","      <td>26</td>\n","      <td>115</td>\n","      <td>31.1</td>\n","      <td>0.205</td>\n","      <td>41</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>7</td>\n","      <td>147</td>\n","      <td>76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39.4</td>\n","      <td>0.257</td>\n","      <td>43</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>1</td>\n","      <td>97</td>\n","      <td>66</td>\n","      <td>15</td>\n","      <td>140</td>\n","      <td>23.2</td>\n","      <td>0.487</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>13</td>\n","      <td>145</td>\n","      <td>82</td>\n","      <td>19</td>\n","      <td>110</td>\n","      <td>22.2</td>\n","      <td>0.245</td>\n","      <td>57</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>5</td>\n","      <td>117</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>34.1</td>\n","      <td>0.337</td>\n","      <td>38</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>738</th>\n","      <td>2</td>\n","      <td>99</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>160</td>\n","      <td>36.6</td>\n","      <td>0.453</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>739</th>\n","      <td>1</td>\n","      <td>102</td>\n","      <td>74</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>39.5</td>\n","      <td>0.293</td>\n","      <td>42</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>740</th>\n","      <td>11</td>\n","      <td>120</td>\n","      <td>80</td>\n","      <td>37</td>\n","      <td>150</td>\n","      <td>42.3</td>\n","      <td>0.785</td>\n","      <td>48</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>741</th>\n","      <td>3</td>\n","      <td>102</td>\n","      <td>44</td>\n","      <td>20</td>\n","      <td>94</td>\n","      <td>30.8</td>\n","      <td>0.400</td>\n","      <td>26</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>742</th>\n","      <td>1</td>\n","      <td>109</td>\n","      <td>58</td>\n","      <td>18</td>\n","      <td>116</td>\n","      <td>28.5</td>\n","      <td>0.219</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>743</th>\n","      <td>9</td>\n","      <td>140</td>\n","      <td>94</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>32.7</td>\n","      <td>0.734</td>\n","      <td>45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>744</th>\n","      <td>13</td>\n","      <td>153</td>\n","      <td>88</td>\n","      <td>37</td>\n","      <td>140</td>\n","      <td>40.6</td>\n","      <td>1.174</td>\n","      <td>39</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>745</th>\n","      <td>12</td>\n","      <td>100</td>\n","      <td>84</td>\n","      <td>33</td>\n","      <td>105</td>\n","      <td>30.0</td>\n","      <td>0.488</td>\n","      <td>46</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>746</th>\n","      <td>1</td>\n","      <td>147</td>\n","      <td>94</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>49.3</td>\n","      <td>0.358</td>\n","      <td>27</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>747</th>\n","      <td>1</td>\n","      <td>81</td>\n","      <td>74</td>\n","      <td>41</td>\n","      <td>57</td>\n","      <td>46.3</td>\n","      <td>1.096</td>\n","      <td>32</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>748</th>\n","      <td>3</td>\n","      <td>187</td>\n","      <td>70</td>\n","      <td>22</td>\n","      <td>200</td>\n","      <td>36.4</td>\n","      <td>0.408</td>\n","      <td>36</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>749</th>\n","      <td>6</td>\n","      <td>162</td>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24.3</td>\n","      <td>0.178</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>750</th>\n","      <td>4</td>\n","      <td>136</td>\n","      <td>70</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>31.2</td>\n","      <td>1.182</td>\n","      <td>22</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>751</th>\n","      <td>1</td>\n","      <td>121</td>\n","      <td>78</td>\n","      <td>39</td>\n","      <td>74</td>\n","      <td>39.0</td>\n","      <td>0.261</td>\n","      <td>28</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>752</th>\n","      <td>3</td>\n","      <td>108</td>\n","      <td>62</td>\n","      <td>24</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0.223</td>\n","      <td>25</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>753</th>\n","      <td>0</td>\n","      <td>181</td>\n","      <td>88</td>\n","      <td>44</td>\n","      <td>510</td>\n","      <td>43.3</td>\n","      <td>0.222</td>\n","      <td>26</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>754</th>\n","      <td>8</td>\n","      <td>154</td>\n","      <td>78</td>\n","      <td>32</td>\n","      <td>0</td>\n","      <td>32.4</td>\n","      <td>0.443</td>\n","      <td>45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>755</th>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>88</td>\n","      <td>39</td>\n","      <td>110</td>\n","      <td>36.5</td>\n","      <td>1.057</td>\n","      <td>37</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>756</th>\n","      <td>7</td>\n","      <td>137</td>\n","      <td>90</td>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>32.0</td>\n","      <td>0.391</td>\n","      <td>39</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>757</th>\n","      <td>0</td>\n","      <td>123</td>\n","      <td>72</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>36.3</td>\n","      <td>0.258</td>\n","      <td>52</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>758</th>\n","      <td>1</td>\n","      <td>106</td>\n","      <td>76</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>37.5</td>\n","      <td>0.197</td>\n","      <td>26</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>759</th>\n","      <td>6</td>\n","      <td>190</td>\n","      <td>92</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>35.5</td>\n","      <td>0.278</td>\n","      <td>66</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>760</th>\n","      <td>2</td>\n","      <td>88</td>\n","      <td>58</td>\n","      <td>26</td>\n","      <td>16</td>\n","      <td>28.4</td>\n","      <td>0.766</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>761</th>\n","      <td>9</td>\n","      <td>170</td>\n","      <td>74</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>44.0</td>\n","      <td>0.403</td>\n","      <td>43</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>762</th>\n","      <td>9</td>\n","      <td>89</td>\n","      <td>62</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>22.5</td>\n","      <td>0.142</td>\n","      <td>33</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>10</td>\n","      <td>101</td>\n","      <td>76</td>\n","      <td>48</td>\n","      <td>180</td>\n","      <td>32.9</td>\n","      <td>0.171</td>\n","      <td>63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>2</td>\n","      <td>122</td>\n","      <td>70</td>\n","      <td>27</td>\n","      <td>0</td>\n","      <td>36.8</td>\n","      <td>0.340</td>\n","      <td>27</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>5</td>\n","      <td>121</td>\n","      <td>72</td>\n","      <td>23</td>\n","      <td>112</td>\n","      <td>26.2</td>\n","      <td>0.245</td>\n","      <td>30</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>1</td>\n","      <td>126</td>\n","      <td>60</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>30.1</td>\n","      <td>0.349</td>\n","      <td>47</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>1</td>\n","      <td>93</td>\n","      <td>70</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>30.4</td>\n","      <td>0.315</td>\n","      <td>23</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 9 columns</p>\n","</div>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"yPZ8swohksne","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0c850a53-42a4-4b1a-aa2d-8a01d31c05bb","executionInfo":{"status":"ok","timestamp":1587724418787,"user_tz":-120,"elapsed":579,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["data.shape"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 9)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"Kg2NJcPkRN5H","colab_type":"text"},"source":["## 1. Univariate Selection"]},{"cell_type":"markdown","metadata":{"id":"BaoeTaNARN5I","colab_type":"text"},"source":["The scikit-learn library provides the `SelectKBest` class (info [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest)) that can be used with a suite of different statistical tests to select a specific number of features. \n","\n","The example below uses the chi-squared (chi2) statistical test for non-negative features to select 4 of the best features from the Pima Indians onset of diabetes dataset."]},{"cell_type":"code","metadata":{"id":"evZ0LUW9RN5K","colab_type":"code","colab":{}},"source":["#from pandas import read_csv\n","from numpy import set_printoptions\n","\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTs-DqyQRN5P","colab_type":"code","colab":{}},"source":["array = data.values\n","X = array[:,0:8]\n","Y = array[:,8]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xavljlu0lAR3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cf44d09c-708f-4196-e142-e5b865f09f3c","executionInfo":{"status":"ok","timestamp":1587724435963,"user_tz":-120,"elapsed":831,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["X.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 8)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"jbOHslallCfW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"98f752a8-27ec-41a2-9376-289c30d026b6","executionInfo":{"status":"ok","timestamp":1587724437667,"user_tz":-120,"elapsed":561,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["Y.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768,)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Z17GQmcbRN5T","colab_type":"code","colab":{}},"source":["# chi2 to select the best k=..\n","test = SelectKBest(score_func=chi2, k=3)\n","fit = test.fit(X, Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xXadTD4RN5X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2c0d9a94-ea8d-4aae-8a94-a56264d6a9ea","executionInfo":{"status":"ok","timestamp":1587724482622,"user_tz":-120,"elapsed":514,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["# summarize scores\n","set_printoptions(precision=3)\n","print(fit.scores_)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g8AVEa39RN5f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c395a277-68c4-4b6a-c50e-08f1d8ca4d59","executionInfo":{"status":"ok","timestamp":1587724494940,"user_tz":-120,"elapsed":632,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["names[:-1]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"lNl3O2YFRN5j","colab_type":"text"},"source":["So, the **k(=3) best ones** seems to be: **plas, test, age**."]},{"cell_type":"markdown","metadata":{"id":"oFY3cxqIlNR4","colab_type":"text"},"source":["[NOTE]: If you want to transform it, you see that change of shape.. (careful, this is powerful..) "]},{"cell_type":"code","metadata":{"id":"anIiC5delLnZ","colab_type":"code","colab":{}},"source":["X_new = SelectKBest(score_func=chi2, k=3).fit_transform(X, Y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQduw3nklLkO","colab_type":"code","colab":{}},"source":["X_new.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9xUrPpjlLhZ","colab_type":"code","colab":{}},"source":["X_new"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQ8cZXbYlz3p","colab_type":"text"},"source":["Let's go back on track."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"q6IpDyssRN5k","colab_type":"code","colab":{}},"source":["# summarize selected features\n","X_new1 = fit.transform(X)\n","print(X_new1[0:10,:])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tRlOWtD7mU_I","colab_type":"text"},"source":["You can do all the bove in one shot with `fit_transform` (careful, often this is dangerous..)"]},{"cell_type":"code","metadata":{"id":"7waiPBLXmU7z","colab_type":"code","colab":{}},"source":["X_new2 = SelectKBest(score_func=chi2, k=3).fit_transform(X,Y)\n","print(X_new2[0:10,:])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj-JUxDxRN5u","colab_type":"text"},"source":["## 2. Recursive Feature Elimination"]},{"cell_type":"markdown","metadata":{"id":"8SSPSZcLRN5v","colab_type":"text"},"source":["\n","More about the RFE class in the scikit-learn documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE)."]},{"cell_type":"code","metadata":{"id":"FP-jW8WKRN5w","colab_type":"code","colab":{}},"source":["from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LogisticRegression"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Oc1qtNuiRN50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"cc79d074-28a7-4d25-ae70-e7cc7894805a","executionInfo":{"status":"ok","timestamp":1587724687667,"user_tz":-120,"elapsed":527,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["# Feature Extraction with RFE\n","model = LogisticRegression(solver = 'lbfgs', max_iter = 500)\n","rfe = RFE(model, 3)    # my choice: seek for 3 features\n","fit = rfe.fit(X, Y)\n","print(\"Num Features: %d\" % fit.n_features_)\n","print(\"Selected Features: %s\" % fit.support_)\n","print(\"Feature Ranking: %s\" % fit.ranking_)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Num Features: 3\n","Selected Features: [ True False False False False  True  True False]\n","Feature Ranking: [1 2 4 6 5 1 1 3]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"JlPDPjo0RN53","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"38a0b9c5-704d-4f4e-8c7d-70b0e2692f49","executionInfo":{"status":"ok","timestamp":1587724649695,"user_tz":-120,"elapsed":652,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["names[:-1]"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"ErQenA9ZRN57","colab_type":"text"},"source":["You can see that RFE chose the **top 3 features** as **preg, mass, pedi**."]},{"cell_type":"markdown","metadata":{"id":"IO_oKcAkRN59","colab_type":"text"},"source":["## 3. Feature Importance"]},{"cell_type":"markdown","metadata":{"id":"tQRj9sCKRN59","colab_type":"text"},"source":["\n","More about the ExtraTreesClassifier class can be found in the scikit-learn API [here](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)."]},{"cell_type":"code","metadata":{"id":"juED2qQFRN5-","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import ExtraTreesClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9qC1hbGRN6B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"dd17734c-e08b-4214-8fd3-b7753f405549","executionInfo":{"status":"ok","timestamp":1587724762099,"user_tz":-120,"elapsed":555,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["# Feature Importance with Extra Trees Classifier\n","model = ExtraTreesClassifier()\n","model.fit(X, Y)\n","print(model.feature_importances_)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[0.112 0.211 0.103 0.079 0.078 0.144 0.114 0.16 ]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yOzdbD0URN6F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"57c16e07-ae9f-40db-f083-5f1bf2d02bc9","executionInfo":{"status":"ok","timestamp":1587724762858,"user_tz":-120,"elapsed":638,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["names[:-1]"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"hdFqygZMRN6I","colab_type":"text"},"source":["**The larger the score, the more important the attribute**. The scores suggest at the importance of **plas, mass, age**."]},{"cell_type":"markdown","metadata":{"id":"yqG9Uyk8RN6L","colab_type":"text"},"source":["## 4. Principal Component Analysis"]},{"cell_type":"markdown","metadata":{"id":"ywrBymoVRN6M","colab_type":"text"},"source":["\n","\n","More about the PCA class in scikit-learn can be found in its API documentation [here](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."]},{"cell_type":"code","metadata":{"id":"Q0ujqO0sRN6N","colab_type":"code","colab":{}},"source":["from sklearn.decomposition import PCA"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"KMEyi5QLRN6a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f7e40727-3fb5-4719-eac6-e9edc69029f0","executionInfo":{"status":"ok","timestamp":1587724810854,"user_tz":-120,"elapsed":718,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["# Feature Extraction with PCA\n","pca = PCA(n_components=3)\n","fit = pca.fit(X)\n","# summarize components\n","print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Explained Variance: [0.889 0.062 0.026]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"aXKNLuSlRN6f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"e4fdf904-84cf-420f-ab30-ad152bd466b1","executionInfo":{"status":"ok","timestamp":1587724811360,"user_tz":-120,"elapsed":558,"user":{"displayName":"Daniele Bonacorsi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWBsRbQFtIRjciBi-aFy9qOKzprHfbmXdS8BQD0A=s64","userId":"01397661520201218305"}}},"source":["print(fit.components_)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[[-2.022e-03  9.781e-02  1.609e-02  6.076e-02  9.931e-01  1.401e-02\n","   5.372e-04 -3.565e-03]\n"," [-2.265e-02 -9.722e-01 -1.419e-01  5.786e-02  9.463e-02 -4.697e-02\n","  -8.168e-04 -1.402e-01]\n"," [-2.246e-02  1.434e-01 -9.225e-01 -3.070e-01  2.098e-02 -1.324e-01\n","  -6.400e-04 -1.255e-01]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dnqlWtnLRN6j","colab_type":"text"},"source":["You can see that the transformed dataset (3 principal components) bear little resemblance to the source data! It is a completely different approach, valuable mainly if you need to reduce the dimensions and the complexity of the problem."]},{"cell_type":"markdown","metadata":{"id":"tfv3IgWJRN6J","colab_type":"text"},"source":["## <font color='red'>Exercise</font>"]},{"cell_type":"markdown","metadata":{"id":"x7ZAW_XxRN6K","colab_type":"text"},"source":["<div class=\"alert alert-block alert-info\">\n","Can you \"compare\" the first 3 methods above and draw any conclusions on the features you would eventually pick?\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"yZ6n38JCxyvE","colab_type":"text"},"source":["1. **plas, test, age**\n","2. **preg, mass, pedi**\n","3. **plas, mass, age**\n","\n","So, voting: plas 2, test 1, age 2, preg 1, pedi 1, mass 2.\n"," \n","What about choosing:\n"," \n","*  **plas age mass**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_bNuZe1tvmb2","colab_type":"text"},"source":["## <font color='green'>Solution</font>"]},{"cell_type":"code","metadata":{"id":"rCRpYsDIvmQW","colab_type":"code","colab":{}},"source":["# insert your observations here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ihX3gbMNRN6k","colab_type":"text"},"source":["## Summary"]},{"cell_type":"markdown","metadata":{"id":"DUoPeiP5RN6k","colab_type":"text"},"source":["What we did:\n","\n","* we explored feature selection for preparing ML data in Python with scikit-learn, and we discovered 4 different automatic feature selection techniques."]},{"cell_type":"markdown","metadata":{"id":"5OuvxuzuRN6l","colab_type":"text"},"source":["## What's next "]},{"cell_type":"markdown","metadata":{"id":"_5iQYc30RN6m","colab_type":"text"},"source":["Now we will start looking at how to evaluate ML algorithms on your dataset, starting from discovering resampling methods that can be used to estimate the performance of a ML algorithm on unseen data."]}]}